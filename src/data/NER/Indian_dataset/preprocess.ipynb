{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_df = pd.DataFrame(columns = ['word', 'tag'])\n",
    "dev_df = pd.DataFrame(columns = ['word', 'tag'])\n",
    "test_df = pd.DataFrame(columns = ['word', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train.csv\", names = ['word', 'tag'], sep = ',')\n",
    "test = pd.read_csv(\"test.csv\", names = ['word', 'tag'], sep = ',')\n",
    "dev = pd.read_csv(\"dev.csv\",  names = ['word', 'tag'], sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 15 16:52:40 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 390.87                 Driver Version: 390.87                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 67%   84C    P2    90W / 250W |   7299MiB / 11170MiB |     39%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 76%   87C    P2   125W / 250W |   1243MiB / 11178MiB |     48%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 79%   89C    P2   207W / 250W |   3404MiB / 11178MiB |     98%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 78%   87C    P2   190W / 250W |   4333MiB / 11178MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.txt', header=False, index=False, sep = ' ')\n",
    "dev.to_csv('dev.txt', header=False, index=False, sep = ' ')\n",
    "test.to_csv('test.txt', header=False, index=False, sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open('trainset.txt', encoding=\"utf-8\")\n",
    "i = 0\n",
    "for line in fh:\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vika/targer/data/NER/Indian_dataset\n"
     ]
    }
   ],
   "source": [
    "an integer is required, not dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "fh = open('trainset.txt', encoding=\"utf-8\")\n",
    "i = 0\n",
    "for line in fh:\n",
    "    # in python 2\n",
    "    # print line\n",
    "    # in python 3\n",
    "    a = line.split()\n",
    "    i +=1\n",
    "    if (i%1000 == 0):\n",
    "        print (i)\n",
    "    for elem in a:\n",
    "        triple = elem.split(\"_\")\n",
    "        #print(triple)   \n",
    "        #if (triple[3] == 'NONE'):\n",
    "        try:\n",
    "            if (i < 24000 ):\n",
    "                train_df = train_df.append({'word':triple[0], 'tag':triple[2]}, ignore_index=True)              \n",
    "            #else:\n",
    "                #dev_df = dev_df.append({'word':triple[0], 'tag':triple[2]}, ignore_index=True) \n",
    "        except:\n",
    "            print (triple)\n",
    "    if (i < 24000 ):\n",
    "        train_df = train_df.append({'word':'', 'tag':''}, ignore_index=True) \n",
    "    #else:\n",
    "        #dev_df = dev_df.append({'word':'', 'tag':''}, ignore_index=True) \n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472608"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>however</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it</td>\n",
       "      <td>PROD1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>be</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>better</td>\n",
       "      <td>PRED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>so</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>many</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ways</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>such</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>as</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>image</td>\n",
       "      <td>ASP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>quality</td>\n",
       "      <td>ASP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>and</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>handle</td>\n",
       "      <td>ASP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>that</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>i</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>have</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>to</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>say</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>i</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>think</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>it</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>be</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>only</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>marginally</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>overpriced</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>i</td>\n",
       "      <td>PROD1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>upgraded</td>\n",
       "      <td>PRED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>from</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word    tag\n",
       "0      however   NONE\n",
       "1           it  PROD1\n",
       "2           be   NONE\n",
       "3       better   PRED\n",
       "4           in   NONE\n",
       "5           so   NONE\n",
       "6         many   NONE\n",
       "7         ways   NONE\n",
       "8         such   NONE\n",
       "9           as   NONE\n",
       "10       image    ASP\n",
       "11     quality    ASP\n",
       "12         and   NONE\n",
       "13      handle    ASP\n",
       "14        that   NONE\n",
       "15           i   NONE\n",
       "16        have   NONE\n",
       "17          to   NONE\n",
       "18         say   NONE\n",
       "19           i   NONE\n",
       "20       think   NONE\n",
       "21          it   NONE\n",
       "22          be   NONE\n",
       "23        only   NONE\n",
       "24  marginally   NONE\n",
       "25  overpriced   NONE\n",
       "26                   \n",
       "27           i  PROD1\n",
       "28    upgraded   PRED\n",
       "29        from   NONE"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('test.csv', index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.csv', index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.to_csv('dev.csv', index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20013"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df=pd.read_csv('test.csv')\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vika/targer/data/NER/Indian_dataset\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import sys\n",
    "sys.path.append(\"/home/vika/targer/\")\n",
    "from src.classes.utils import get_words_num\n",
    "\n",
    "\n",
    "def read_data(fn, verbose=True, column_no=-1, splitter = ','):\n",
    "    word_sequences = list()\n",
    "    tag_sequences = list()\n",
    "    with codecs.open(fn, 'r', 'utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        print (len(lines))\n",
    "    curr_words = list()\n",
    "    curr_tags = list()\n",
    "    for k in range(len(lines)):\n",
    "        #print (lines[k])\n",
    "        line = lines[k].strip()\n",
    "        if len(line) == 1 or line.startswith('-DOCSTART-'): # new sentence or new document\n",
    "            if len(curr_words) > 0:\n",
    "                word_sequences.append(curr_words)\n",
    "                tag_sequences.append(curr_tags)\n",
    "                curr_words = list()\n",
    "                curr_tags = list()\n",
    "            continue\n",
    "        strings = line.split(',')\n",
    "        #print (strings)\n",
    "        word = strings[0]\n",
    "        #print (\"word\", word)\n",
    "        tag = strings[column_no] # be default, we take the last tag\n",
    "        #print (\"word\", tag)\n",
    "        curr_words.append(word)\n",
    "        curr_tags.append(tag)\n",
    "        if k == len(lines) - 1:\n",
    "            word_sequences.append(curr_words)\n",
    "            tag_sequences.append(curr_tags)\n",
    "    if verbose:\n",
    "        print('Loading from %s: %d samples, %d words.' % (fn, len(word_sequences), get_words_num(word_sequences)))\n",
    "    return word_sequences, tag_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20014\n",
      "Loading from test.csv: 1093 samples, 18921 words.\n"
     ]
    }
   ],
   "source": [
    "a, b = read_data('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
